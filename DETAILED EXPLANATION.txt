üìò Project Explanation: Prediction and Explainability of Student Academic Performance Using Machine Learning
1. Introduction and Problem Statement

In the education domain, institutions aim not only to evaluate student performance but also to understand which factors influence academic outcomes. Traditional statistical methods provide limited insights and often fail to capture complex relationships between multiple factors such as demographics, family background, study habits, and lifestyle choices.

Machine learning models can make accurate predictions, but many of them operate as black boxes, meaning they provide predictions without explaining how those predictions were made. This lack of transparency reduces trust, especially in sensitive domains like education.

The objective of this project is:

To predict overall student academic performance using machine learning.

To explain the predictions using Explainable AI (XAI) techniques, specifically SHAP.

2. Dataset Description

This project uses two real-world datasets:

student-mat.csv ‚Äì student performance in Mathematics

student-por.csv ‚Äì student performance in Portuguese

Each dataset contains:

Demographic details (age, sex, address)

Family background (parents‚Äô education, jobs)

Academic behavior (study time, failures, absences)

Lifestyle factors (free time, alcohol consumption)

Grades (G1, G2, G3)

These datasets are widely used in academic research, making the project realistic and credible.

3. Data Merging and Motivation

The two datasets were merged using common demographic and family-related features such as age, parental education, study habits, and lifestyle attributes.

Purpose of merging:

To analyze students with similar backgrounds across two subjects

To study the relationship between Math and Portuguese performance

To create a holistic view of academic achievement

4. Exploratory Data Analysis (EDA)

A scatter plot was created between:

Math final grade (G3_math)

Portuguese final grade (G3_port)

Additionally, correlation was computed to quantify the relationship.

Insight:

Students who perform well in one subject generally tend to perform well in the other, justifying the creation of a combined performance metric.

5. Feature Engineering

A new target variable was created:

G3_avg = average of Math and Portuguese final grades

Why this is important:

Represents overall academic performance

Reduces subject-specific bias

Provides a more stable prediction target

6. Feature Selection and Data Leakage Prevention

Intermediate grades (G1, G2, G3) were removed from features.

Reason:

These grades directly determine the final outcome

Including them would cause data leakage

The model should predict performance using behavioral and background features only

This makes the model realistic and ethically sound.

7. Data Preprocessing

Categorical variables were converted using one-hot encoding.

pd.get_dummies(X, drop_first=True)


This step ensures:

Compatibility with machine learning algorithms

No loss of categorical information

Reduced multicollinearity

8. Train‚ÄìTest Split

The dataset was split into:

80% training data

20% testing data

This ensures:

The model learns patterns from training data

Performance evaluation is unbiased

9. Model Selection: Random Forest Regressor

A Random Forest Regressor was chosen because:

It captures non-linear relationships

It is robust to noise

It performs well with mixed feature types

It provides strong predictive performance

10. Model Training and Evaluation

The model was trained on the training dataset and evaluated using Root Mean Squared Error (RMSE).

Why RMSE:

It is in the same unit as grades

Penalizes large prediction errors

Commonly used in regression problems

This metric indicates how close the predictions are to actual student performance.

11. Feature Importance Analysis

Random Forest feature importance was used to identify:

Which features influence predictions the most

Whether the model aligns with domain knowledge

Features such as study time, failures, absences, and parental education emerged as important, validating the model‚Äôs behavior.

12. Black Box Concept in Machine Learning

A black box model is a model where:

Inputs and outputs are visible

The internal decision-making process is not easily interpretable

Random Forest is considered a black box because:

It uses many decision trees

Each tree makes independent decisions

The final output is an aggregation of all trees

This makes it difficult for humans to understand why a particular prediction was made.

13. Explainable AI and SHAP

To address the black box problem, SHAP (SHapley Additive exPlanations) was used.

SHAP explains predictions by assigning each feature a contribution value based on game theory.

SHAP principle:
Prediction = Base Value + Sum of SHAP Values


Where:

Base value is the average prediction

SHAP values show how each feature increases or decreases the prediction

14. Interpretation of SHAP Output

From SHAP visualizations:

Features at the top are globally most important

Positive SHAP values increase predicted performance

Negative SHAP values decrease predicted performance

Color indicates feature magnitude (high or low values)

This allows:

Global understanding of model behavior

Local explanation for individual students

15. Significance of the Project

This project demonstrates:

Real-world data handling

Proper feature engineering

Avoidance of data leakage

Robust model training and evaluation

Use of Explainable AI for transparency

It transforms a black box model into a trustworthy and interpretable system, which is crucial in education-related applications.

16. Final Summary (One-paragraph for faculty)

‚ÄúThis project predicts overall student academic performance using a Random Forest regression model trained on demographic, behavioral, and lifestyle data. By merging Math and Portuguese datasets and engineering a combined performance metric, the model captures holistic academic outcomes. To address the black box nature of machine learning models, SHAP was used to explain both global and individual predictions, making the model transparent, interpretable, and suitable for real-world educational analysis.‚Äù



 